PROJECT_NAME := ftrs-dos
ENVIRONMENT ?= dev
SERVICE ?= is-performance
PYTHON_VERSION ?= 3.12
TEST_DIR := parameter_files
WORKSPACE_PARAMETER_FILES_BUCKET := ${PROJECT_NAME}-${ENVIRONMENT}-${SERVICE}-parameter-files-bucket-${WORKSPACE}
MAIN_PARAMETER_FILES_BUCKET := ${PROJECT_NAME}-${ENVIRONMENT}-${SERVICE}-parameter-files-bucket
JMETER_PLUGINS_MANAGER_VERSION := 1.11
CMDRUNNER_VERSION := 2.3
AWS_REGION ?= eu-west-2

install: config

config:
	make _install-dependencies
	make install-jmeter-plugins
	make install-jmeter-dependencies

install-jmeter-plugins: ## Installs jmeter plugin manager, tools and required plugins
	echo "Installing jmeter plugin manager"
	curl --output-dir  $$(asdf where jmeter)/lib/ext -O https://repo1.maven.org/maven2/kg/apc/jmeter-plugins-manager/${JMETER_PLUGINS_MANAGER_VERSION}/jmeter-plugins-manager-${JMETER_PLUGINS_MANAGER_VERSION}.jar

	echo "Installing jmeter command runner"
	curl --output-dir  $$(asdf where jmeter)/lib -O https://repo1.maven.org/maven2/kg/apc/cmdrunner/${CMDRUNNER_VERSION}/cmdrunner-${CMDRUNNER_VERSION}.jar

	echo "Setting up jmeter command runner"
	java -cp $$(asdf where jmeter)/lib/ext/jmeter-plugins-manager-${JMETER_PLUGINS_MANAGER_VERSION}.jar org.jmeterplugins.repository.PluginManagerCMDInstaller

	echo "Installing jmeter plugins"
	/bin/bash $$(asdf where jmeter)/bin/PluginsManagerCMD.sh install jpgc-graphs-basic,jpgc-graphs-additional

install-jmeter-dependencies: ## Installs jmeter dependencies
	echo "Installing jmeter dependencies"
	curl --output-dir  $$(asdf where jmeter)/lib -O https://repo1.maven.org/maven2/com/auth0/java-jwt/4.5.0/java-jwt-4.5.0.jar

performance-test-mtls: ##[PLAN_NAME=name of jmeter plan] [PFX_PATH=path to pfk file][PFX_PASSWORD=password for pfx file] [ENDPOINT=endpoint of APIs]
	echo "running performance tests against ${PLAN_NAME}..."
	jmeter -n -t ${PLAN_NAME}.jmx -J serviceendpoint=${ENDPOINT} -f -l result.jtl -e -o "report" -D javax.net.ssl.keyStore="${PFX_PATH}" -D javax.net.ssl.keyStorePassword="${PFX_PASSWORD}";

performance-test-jwt: ##[PLAN_NAME=name of jmeter plan] [APIM_ENV=environment for APIM proxy][APIKEY=API key for APIM proxy [KID=Name of key for JWT token]
	echo "running performance tests against ${PLAN_NAME}..."
	jmeter -n -t ${PLAN_NAME}.jmx -J apim_env=${APIM_ENV} -J apikey=${APIKEY} -J kid=${KID} -f -l result.jtl -e -o "report" ;

performance-test-dashboard: ##[TEST_DATA=name of performance test data jtl file]
	echo "generating performance dashboard for ${TEST_DATA}..."
	jmeter -g ${TEST_DATA}.jtl -f -e -o reports

download-workspace-performance-parameter-files: ##[AWS_REGION=aws region] [WORKSPACE=workspace name]
	echo "PROJECT_NAME: ${PROJECT_NAME}"
	echo "ENVIRONMENT: ${ENVIRONMENT}"
	echo "SERVICE: ${SERVICE}"
	echo "WORKSPACE_PARAMETER_FILES_BUCKET: ${WORKSPACE_PARAMETER_FILES_BUCKET}"
	aws s3 cp s3://${WORKSPACE_PARAMETER_FILES_BUCKET} --region $(AWS_REGION) ${TEST_DIR}/ --recursive

download-main-performance-parameter-files: ##[AWS_REGION=aws region]
	echo "PROJECT_NAME: ${PROJECT_NAME}"
	echo "ENVIRONMENT: ${ENVIRONMENT}"
	echo "SERVICE: ${SERVICE}"
	echo "MAIN_PARAMETER_FILES_BUCKET: ${MAIN_PARAMETER_FILES_BUCKET}"
	aws s3 cp s3://${MAIN_PARAMETER_FILES_BUCKET} --region $(AWS_REGION) ${TEST_DIR}/ --recursive

copy-performance-parameter-files: ##[AWS_REGION=aws region] [WORKSPACE=workspace name]
	echo "PROJECT_NAME: ${PROJECT_NAME}"
	echo "ENVIRONMENT: ${ENVIRONMENT}"
	echo "SERVICE: ${SERVICE}"
	echo "WORKSPACE_PARAMETER_FILES_BUCKET: ${WORKSPACE_PARAMETER_FILES_BUCKET}"
	echo "MAIN_PARAMETER_FILES_BUCKET: ${MAIN_PARAMETER_FILES_BUCKET}"
	aws s3 cp s3://${MAIN_PARAMETER_FILES_BUCKET} --region $(AWS_REGION) s3://${WORKSPACE_PARAMETER_FILES_BUCKET} --region $(AWS_REGION) --recursive

_install-dependency: # Install asdf dependency - mandatory: name=[listed in the '.tool-versions' file]; optional: version=[if not listed]
	echo ${name}
	asdf plugin add ${name} ||:
	asdf plugin update ${name} ||:
	asdf install ${name} $(or ${version},)

_install-dependencies: # Install all the dependencies listed in .tool-versions
	for plugin in $$(grep ^[a-z] .tool-versions | sed 's/[[:space:]].*//'); do \
		make _install-dependency name="$${plugin}"; \
	done

jmeter-ec2-id:
	@ID="$(JMETER_INSTANCE_ID)"; \
	if [ -z "$$ID" ]; then echo "JMETER_INSTANCE_ID is required"; exit 1; fi; \
	echo "JMeter EC2 instance id: $$ID"

jmeter-private-ip:
	@ID="$(JMETER_INSTANCE_ID)"; \
	if [ -z "$$ID" ]; then echo "JMETER_INSTANCE_ID is required"; exit 1; fi; \
	IP=$$(aws ec2 describe-instances --region $(AWS_REGION) --instance-ids "$$ID" \
		--query 'Reservations[0].Instances[0].PrivateIpAddress' --output text 2>/dev/null | tr -d '[:space:]'); \
	echo "JMeter EC2 private IP: $$IP"

jmeter-start-instance: ## [JMETER_INSTANCE_ID=i-xxxxxxxxxxxxxxxxx] Start the JMeter EC2 instance and wait until running
	@ID="$(JMETER_INSTANCE_ID)"; \
	if [ -z "$$ID" ]; then echo "JMETER_INSTANCE_ID is required"; exit 1; fi; \
	aws ec2 start-instances --region $(AWS_REGION) --instance-ids "$$ID" >/dev/null; \
	aws ec2 wait instance-running --region $(AWS_REGION) --instance-ids "$$ID"; \
	echo "JMeter instance started: $$ID"

jmeter-stop-instance: ## [JMETER_INSTANCE_ID=i-xxxxxxxxxxxxxxxxx] Stop the JMeter EC2 instance and wait until stopped
	@ID="$(JMETER_INSTANCE_ID)"; \
	if [ -z "$$ID" ]; then echo "JMETER_INSTANCE_ID is required"; exit 1; fi; \
	aws ec2 stop-instances --region $(AWS_REGION) --instance-ids "$$ID" >/dev/null; \
	aws ec2 wait instance-stopped --region $(AWS_REGION) --instance-ids "$$ID"; \
	echo "JMeter instance stopped: $$ID"

jmeter-version-remote: ## [JMETER_INSTANCE_ID=i-xxxxxxxxxxxxxxxxx] Print JMeter version number from /home/ssm-user on the EC2 using SSM
	@ID="$(JMETER_INSTANCE_ID)"; \
	if [ -z "$$ID" ]; then echo "JMETER_INSTANCE_ID is required"; exit 1; fi; \
	aws ssm start-session --region $(AWS_REGION) --target "$$ID" --document-name AWS-StartInteractiveCommand --parameters 'command=["bash -lc \"cd /home/ssm-user && echo && echo '\''jmeter\\ version'\'' &&  echo '\''--------------'\'' && jmeter -v 2>&1 | grep -Eo '\''[0-9]+(\\.[0-9]+)+'\'' | tail -n1\""]'

jmeter-ssm-shell: ## [JMETER_INSTANCE_ID=i-xxxxxxxxxxxxxxxxx] Open an interactive SSM shell to the JMeter EC2 instance
	@ID="$(JMETER_INSTANCE_ID)"; \
	if [ -z "$$ID" ]; then echo "JMETER_INSTANCE_ID is required"; exit 1; fi; \
	aws ssm start-session --region $(AWS_REGION) --target "$$ID"

jmeter-copy-ssm-inline: ## [JMETER_INSTANCE_ID=i-xxxxxxxxxxxxxxxxx] [FILE=jmeter_test_plan.jmx] [DEST=jmeter_test_plan.jmx]
	@ID="$(JMETER_INSTANCE_ID)"; \
	if [ -z "$$ID" ]; then echo "JMETER_INSTANCE_ID is required"; exit 1; fi; \
	FILE="${FILE}"; if [ -z "$$FILE" ]; then FILE=jmeter_test_plan.jmx; fi; \
	DEST="${DEST}"; if [ -z "$$DEST" ]; then DEST=$$(basename "$$FILE"); fi; \
	if [ ! -f "$$FILE" ]; then ALT="tests/performance/$$(basename "$$FILE")"; if [ -f "$$ALT" ]; then FILE="$$ALT"; else echo "File '$$FILE' not found"; exit 1; fi; fi; \
	B64=$$(base64 < "$$FILE" | tr -d '\n'); \
	echo "Uploading '$$FILE' to EC2:/home/ssm-user/$$DEST via SSM inline"; \
	PARAMS_FILE=$$(mktemp); \
	printf '%s\n' '{' '  "commands": [' '    "bash -lc \"printf %s '\''__B64__'\'' | base64 -d > /home/ssm-user/__DEST__ && chown ssm-user:ssm-user /home/ssm-user/__DEST__ && ls -l /home/ssm-user/__DEST__\""' '  ]' '}' > "$$PARAMS_FILE"; \
	B64_ESC=$$(printf '%s' "$$B64" | sed -e 's/[&|]/\\\&/g'); \
	DEST_ESC=$$(printf '%s' "$$DEST" | sed -e 's/[&|]/\\\&/g'); \
	sed -i.bak -e "s|__B64__|$$B64_ESC|g" -e "s|__DEST__|$$DEST_ESC|g" "$$PARAMS_FILE"; rm -f "$$PARAMS_FILE.bak"; \
	CMD_ID=$$(aws ssm send-command --region $(AWS_REGION) --instance-ids "$$ID" \
		--document-name AWS-RunShellScript \
		--parameters file://$$PARAMS_FILE \
		--query 'Command.CommandId' --output text); \
	rm -f "$$PARAMS_FILE"; \
	if [ -z "$$CMD_ID" ] || [ "$$CMD_ID" = "None" ]; then echo "SSM send-command failed"; exit 1; fi; \
	if ! aws ssm wait command-executed --region $(AWS_REGION) --instance-id "$$ID" --command-id "$$CMD_ID"; then \
		echo "SSM command execution failed; fetching invocation logs..."; \
		aws ssm get-command-invocation --region $(AWS_REGION) --command-id "$$CMD_ID" --instance-id "$$ID" --output text \
			--query '[Status,StandardOutputContent,StandardErrorContent]' || true; \
		exit 1; \
	fi; \
	echo "File uploaded to /home/ssm-user/$${DEST}"

jmeter-copy-dir-ssm-inline: ## [JMETER_INSTANCE_ID=i-xxxxxxxxxxxxxxxxx] [DIR=parameter_files] [DEST_DIR=] Copy all regular files in DIR to EC2 under /home/ssm-user[/DEST_DIR] using the same inline logic as jmeter-copy-ssm-inline
	@ID="$(JMETER_INSTANCE_ID)"; \
	if [ -z "$$ID" ]; then echo "JMETER_INSTANCE_ID is required"; exit 1; fi; \
	DIR="${DIR}"; if [ -z "$$DIR" ]; then DIR=parameter_files; fi; \
	DIR=$${DIR%/}; \
	if [ ! -d "$$DIR" ]; then ALT="tests/performance/$$(basename "$$DIR")"; if [ -d "$$ALT" ]; then DIR="$$ALT"; else echo "Directory '$$DIR' not found"; exit 1; fi; fi; \
	DEST_DIR="${DEST_DIR}"; \
	for FILE in "$$DIR"/*; do \
		[ -e "$$FILE" ] || continue; \
		if [ ! -f "$$FILE" ]; then continue; fi; \
		DEST=$$(basename "$$FILE"); \
		if [ -n "$$DEST_DIR" ] && [ "$$DEST_DIR" != "." ]; then DEST_PATH="/home/ssm-user/$${DEST_DIR}/$${DEST}"; else DEST_PATH="/home/ssm-user/$${DEST}"; fi; \
		B64=$$(base64 < "$$FILE" | tr -d '\n'); \
		echo "Uploading '$$FILE' to EC2:$$DEST_PATH via SSM inline"; \
		PARAMS_FILE=$$(mktemp); \
		printf '%s\n' '{' '  "commands": [' \
			"    \"bash -lc \\\"set -euo pipefail; DEST_DIR=__DEST_DIR__; DEST_PATH=__DEST_PATH__; if [ -n \\\"$$DEST_DIR\\\" ] && [ \\\"$$DEST_DIR\\\" != \\\".\\\" ]; then install -d -m 0755 -o ssm-user -g ssm-user /home/ssm-user/\\\"$$DEST_DIR\\\"; fi; printf %s __B64__ | base64 -d > \\\"$$DEST_PATH\\\" && chown ssm-user:ssm-user \\\"$$DEST_PATH\\\"; ls -l \\\"$$DEST_PATH\\\"\\\"\"" \
			'  ]' '}' > "$$PARAMS_FILE"; \
		B64_ESC=$$(printf '%s' "$$B64" | sed -e 's/[&|]/\\\&/g'); \
		DEST_DIR_ESC=$$(printf '%s' "$$DEST_DIR" | sed -e 's/[&|]/\\\&/g'); \
		DEST_PATH_ESC=$$(printf '%s' "$$DEST_PATH" | sed -e 's/[&|]/\\\&/g'); \
		sed -i.bak \
			-e "s|__B64__|$$B64_ESC|g" \
			-e "s|__DEST_DIR__|$$DEST_DIR_ESC|g" \
			-e "s|__DEST_PATH__|$$DEST_PATH_ESC|g" \
			"$$PARAMS_FILE"; rm -f "$$PARAMS_FILE.bak"; \
		CMD_ID=$$(aws ssm send-command --region $(AWS_REGION) --instance-ids "$$ID" \
			--document-name AWS-RunShellScript \
			--parameters file://$$PARAMS_FILE \
			--query 'Command.CommandId' --output text); \
		rm -f "$$PARAMS_FILE"; \
		if [ -z "$$CMD_ID" ] || [ "$$CMD_ID" = "None" ]; then echo "SSM send-command failed"; exit 1; fi; \
		if ! aws ssm wait command-executed --region $(AWS_REGION) --instance-id "$$ID" --command-id "$$CMD_ID"; then \
			echo "SSM command execution failed; fetching invocation logs..."; \
			aws ssm get-command-invocation --region $(AWS_REGION) --command-id "$$CMD_ID" --instance-id "$$ID" --output text \
				--query '[Status,StandardOutputContent,StandardErrorContent]' || true; \
			exit 1; \
		fi; \
		echo "Uploaded $$DEST_PATH"; \
	done

# Fetch any single file via SSM
jmeter-fetch-file-inline: ## [REMOTE_FILE=result.jtl] [LOCAL_DIR=tests/performance/artifacts] [LOCAL_FILE=<optional>] Fetch any single file via SSM into LOCAL_DIR or to LOCAL_FILE
	@set -euo pipefail; \
	ID="$(JMETER_INSTANCE_ID)"; \
	if [ -z "$$ID" ]; then echo "JMETER_INSTANCE_ID is required"; exit 1; fi; \
	REM="${REMOTE_FILE}"; if [ -z "$$REM" ]; then REM=result.jtl; fi; \
	case "$$REM" in /*) RPATH="$$REM" ;; *) RPATH="/home/ssm-user/$$REM" ;; esac; \
	LFILE="${LOCAL_FILE}"; \
	if [ -n "$$LFILE" ]; then OUTFILE="$$LFILE"; mkdir -p "$$(dirname "$$OUTFILE")"; else \
		ROOT_DIR=$$(git rev-parse --show-toplevel 2>/dev/null || pwd); \
		LDIR="${LOCAL_DIR}"; if [ -z "$$LDIR" ]; then LDIR="$$ROOT_DIR/tests/performance/artifacts"; fi; mkdir -p "$$LDIR"; OUTFILE="$$LDIR/$$(basename "$$RPATH")"; \
	fi; \
	TMPDIR=$$(mktemp -d); B64FILE="$$TMPDIR/file.inline.b64"; \
	echo "Fetching '$$RPATH' via SSM"; \
	RCMD="set -o pipefail; echo __B64_START__; if [ -f \"$$RPATH\" ]; then base64 \"$$RPATH\"; else echo __NO_RESULT__; fi; echo __B64_END__"; \
	PARAMS_FILE="$$TMPDIR/params.json"; \
	ESC_RCMD=$$(printf '%s' "$$RCMD" | sed -e 's/\\/\\\\/g' -e 's/\"/\\\"/g'); \
	printf '%s' '{"command":["bash -lc \"'"$$ESC_RCMD"'\""]}' > "$$PARAMS_FILE"; \
	aws ssm start-session --region $(AWS_REGION) --target "$$ID" \
		--document-name AWS-StartInteractiveCommand \
		--parameters file://"$$PARAMS_FILE" \
		| awk '/__B64_START__/{flag=1;next}/__B64_END__/{flag=0}flag' > "$$B64FILE"; \
	if grep -q "__NO_RESULT__" "$$B64FILE"; then echo "Remote file not found: $$RPATH"; rm -rf "$$TMPDIR"; exit 1; fi; \
	if base64 --decode < "$$B64FILE" > "$$OUTFILE" 2>/dev/null; then :; \
	elif base64 -d < "$$B64FILE" > "$$OUTFILE" 2>/dev/null; then :; \
	elif base64 -D < "$$B64FILE" > "$$OUTFILE" 2>/dev/null; then :; \
	else echo "Failed to decode base64 for '$$RPATH'"; rm -rf "$$TMPDIR"; exit 1; fi; \
	ls -lh "$$OUTFILE" || ls -l "$$OUTFILE"; \
	rm -rf "$$TMPDIR"; \
	echo "Downloaded '$$RPATH' to '$$OUTFILE'"

jmeter-fetch-dir-inline: ## [REMOTE_DIR=artifacts] [LOCAL_DIR=tests/performance/artifacts] Fetch all regular files from REMOTE_DIR into LOCAL_DIR using SSM (indexed loop)
	@set -euo pipefail; \
	ID="$(JMETER_INSTANCE_ID)"; \
	if [ -z "$$ID" ]; then echo "JMETER_INSTANCE_ID is required"; exit 1; fi; \
	REMOTE_DIR="${REMOTE_DIR}"; if [ -z "$$REMOTE_DIR" ]; then REMOTE_DIR=artifacts; fi; \
	case "$$REMOTE_DIR" in /*) RDIR="$$REMOTE_DIR" ;; *) RDIR="/home/ssm-user/$$REMOTE_DIR" ;; esac; \
	LDIR="${LOCAL_DIR}"; if [ -z "$$LDIR" ]; then ROOT_DIR=$$(git rev-parse --show-toplevel 2>/dev/null || pwd); LDIR="$$ROOT_DIR/tests/performance/artifacts"; fi; mkdir -p "$$LDIR"; \
	WORKDIR=$$(mktemp -d); [ -n "$$WORKDIR" ] || { echo "mktemp failed"; exit 1; }; \
	PARAMS="$$WORKDIR/params.list.json"; OUT="$$WORKDIR/files.list"; B64TMP="$$WORKDIR/file.b64"; \
	echo "Listing files in remote directory: $$RDIR"; \
	LIST_CMD=$$(printf '%s' "if [ -d \"$$RDIR\" ]; then find \"$$RDIR\" -maxdepth 1 -type f -printf '%f\\n' | sort; else echo __NO_DIR__; fi"); \
	ESC_LIST_CMD=$$(printf '%s' "$$LIST_CMD" | sed -e 's/\\/\\\\/g' -e 's/"/\\"/g'); \
	printf '%s' '{"commands":["bash -lc \"'"$$ESC_LIST_CMD"'\""]}' > "$$PARAMS"; \
	CMD_ID=$$(aws ssm send-command --region $(AWS_REGION) --instance-ids "$$ID" --document-name AWS-RunShellScript --parameters file://"$$PARAMS" --query 'Command.CommandId' --output text); \
	rm -f "$$PARAMS"; \
	if [ -z "$$CMD_ID" ] || [ "$$CMD_ID" = "None" ]; then echo "SSM send-command failed for listing"; rm -rf "$$WORKDIR"; exit 1; fi; \
	aws ssm wait command-executed --region $(AWS_REGION) --instance-id "$$ID" --command-id "$$CMD_ID"; \
	aws ssm get-command-invocation --region $(AWS_REGION) --instance-id "$$ID" --command-id "$$CMD_ID" --query 'StandardOutputContent' --output text > "$$OUT" || true; \
	if grep -q "__NO_DIR__" "$$OUT" 2>/dev/null; then echo "No remote directory: $$RDIR"; rm -rf "$$WORKDIR"; exit 0; fi; \
	if [ ! -s "$$OUT" ]; then echo "No files found in remote directory: $$RDIR"; rm -rf "$$WORKDIR"; exit 0; fi; \
	CLEAN="$$WORKDIR/files.clean"; \
	tr -d '\r' < "$$OUT" \
		| awk '{gsub(/^[[:space:]]+|[[:space:]]+$$/, ""); if ($$0 ~ /[[:graph:]]/) print $$0}' > "$$CLEAN"; \
	COUNT=$$(wc -l < "$$CLEAN" | tr -d '[:space:]'); \
	echo "Total files: $$COUNT"; \
	FETCHED=0; i=1; \
	while [ "$$i" -le "$$COUNT" ]; do \
		F=$$(sed -n "$${i}p" "$$CLEAN" | tr -d '\r\n'); \
		if [ -z "$$F" ]; then i=$$((i+1)); continue; fi; \
		RPATH="$$RDIR/$$F"; OUTFILE="$$LDIR/$$F"; TMPP=$$(mktemp); [ -n "$$TMPP" ] || { echo "mktemp failed for file $$F"; rm -rf "$$WORKDIR"; exit 1; }; \
		echo "[$$i/$$COUNT] Fetching: $$RPATH -> $$OUTFILE"; \
		FETCH_CMD=$$(printf '%s' "if [ -f \"$$RPATH\" ]; then base64 \"$$RPATH\"; else echo __NO_RESULT__; fi"); \
		ESC_FETCH_CMD=$$(printf '%s' "$$FETCH_CMD" | sed -e 's/\\/\\\\/g' -e 's/"/\\"/g'); \
		printf '%s' '{"commands":["bash -lc \"'"$$ESC_FETCH_CMD"'\""]}' > "$$TMPP"; \
		CMD_ID=$$(aws ssm send-command --region $(AWS_REGION) --instance-ids "$$ID" --document-name AWS-RunShellScript --parameters file://"$$TMPP" --query 'Command.CommandId' --output text); \
		rm -f "$$TMPP"; \
		if [ -z "$$CMD_ID" ] || [ "$$CMD_ID" = "None" ]; then echo "SSM send-command failed for $$RPATH"; rm -rf "$$WORKDIR"; exit 1; fi; \
		aws ssm wait command-executed --region $(AWS_REGION) --instance-id "$$ID" --command-id "$$CMD_ID"; \
		aws ssm get-command-invocation --region $(AWS_REGION) --instance-id "$$ID" --command-id "$$CMD_ID" --query 'StandardOutputContent' --output text > "$$B64TMP" || true; \
		if grep -q "__NO_RESULT__" "$$B64TMP"; then echo "Remote file not found: $$RPATH"; rm -rf "$$WORKDIR"; exit 1; fi; \
		if base64 --decode < "$$B64TMP" > "$$OUTFILE" 2>/dev/null; then :; \
		elif base64 -d < "$$B64TMP" > "$$OUTFILE" 2>/dev/null; then :; \
		elif base64 -D < "$$B64TMP" > "$$OUTFILE" 2>/dev/null; then :; \
		else echo "Failed to decode base64 for '$$RPATH'"; rm -rf "$$WORKDIR"; exit 1; fi; \
		ls -lh "$$OUTFILE" || ls -l "$$OUTFILE"; \
		FETCHED=$$((FETCHED+1)); \
		i=$$((i+1)); \
	done; \
	rm -rf "$$WORKDIR"; \
	echo "Downloaded $$FETCHED files from '$$RDIR' to '$$LDIR' (listed $$COUNT)"

# --- S3 object utilities and Secrets Manager fetch ---

# Upload a single file to S3
s3-upload-file: ## [BUCKET=name] [SRC=local/file] [DEST_KEY=path/in/bucket] [S3_SSE=aws:kms] [S3_KMS_KEY_ID=arn or key-id]
	@if [ -z "$(BUCKET)" ]; then echo "BUCKET is required"; exit 1; fi; \
	if [ -z "$(SRC)" ]; then echo "SRC is required"; exit 1; fi; \
	KEY="$(DEST_KEY)"; if [ -z "$$KEY" ]; then KEY=$$(basename "$(SRC)"); fi; \
	AWS_FLAGS=""; \
	if [ -n "$(S3_SSE)" ]; then AWS_FLAGS="$$AWS_FLAGS --sse $(S3_SSE)"; fi; \
	if [ -n "$(S3_KMS_KEY_ID)" ]; then AWS_FLAGS="$$AWS_FLAGS --sse-kms-key-id $(S3_KMS_KEY_ID)"; fi; \
	echo "Uploading '$(SRC)' to s3://$(BUCKET)/$$KEY"; \
	aws s3 cp "$(SRC)" "s3://$(BUCKET)/$$KEY" --region $(AWS_REGION) $$AWS_FLAGS

# Upload a folder (recursive) to S3
s3-upload-folder: ## [BUCKET=name] [SRC_DIR=local/dir] [DEST_PREFIX=prefix/] [S3_SSE=aws:kms] [S3_KMS_KEY_ID=arn or key-id]
	@if [ -z "$(BUCKET)" ]; then echo "BUCKET is required"; exit 1; fi; \
	DIR="$(SRC_DIR)"; if [ -z "$$DIR" ]; then echo "SRC_DIR is required"; exit 1; fi; \
	PREFIX="$(DEST_PREFIX)"; \
	AWS_FLAGS=""; \
	if [ -n "$(S3_SSE)" ]; then AWS_FLAGS="$$AWS_FLAGS --sse $(S3_SSE)"; fi; \
	if [ -n "$(S3_KMS_KEY_ID)" ]; then AWS_FLAGS="$$AWS_FLAGS --sse-kms-key-id $(S3_KMS_KEY_ID)"; fi; \
	echo "Uploading folder '$$DIR' to s3://$(BUCKET)/$$PREFIX"; \
	aws s3 cp "$$DIR" "s3://$(BUCKET)/$$PREFIX" --recursive --region $(AWS_REGION) $$AWS_FLAGS

# Download a single file from S3
s3-download-file: ## [BUCKET=name] [KEY=path/in/bucket] [DEST=local/path]
	@if [ -z "$(BUCKET)" ]; then echo "BUCKET is required"; exit 1; fi; \
	if [ -z "$(KEY)" ]; then echo "KEY is required"; exit 1; fi; \
	DEST="$(DEST)"; if [ -z "$$DEST" ]; then DEST=$$(basename "$(KEY)"); fi; \
	echo "Downloading s3://$(BUCKET)/$(KEY) to '$$DEST'"; \
	mkdir -p "$$(dirname "$$DEST")" 2>/dev/null || true; \
	aws s3 cp "s3://$(BUCKET)/$(KEY)" "$$DEST" --region $(AWS_REGION)

# Download a folder (recursive) from S3
s3-download-folder: ## [BUCKET=name] [PREFIX=path/prefix/] [DEST_DIR=local/dir]
	@if [ -z "$(BUCKET)" ]; then echo "BUCKET is required"; exit 1; fi; \
	PFX="$(PREFIX)"; if [ -z "$$PFX" ]; then PFX=""; fi; \
	LDIR="$(DEST_DIR)"; if [ -z "$$LDIR" ]; then LDIR=.; fi; \
	echo "Downloading s3://$(BUCKET)/$$PFX to '$$LDIR'"; \
	mkdir -p "$$LDIR"; \
	aws s3 cp "s3://$(BUCKET)/$$PFX" "$$LDIR" --recursive --region $(AWS_REGION)

# Get a secret value from Secrets Manager
secrets-get: ## [SECRET_ID=arn or name] [MODE=raw|json|kv] [OUT=] Fetch the entire secret value (ignores KEY); choose MODE for formatting
	@BIN="$(CURDIR)/bin/secrets_get.sh"; \
	if [ -z "$(SECRET_ID)" ]; then echo "SECRET_ID is required"; exit 1; fi; \
	if [ ! -x "$$BIN" ]; then echo "Helper script not executable: $$BIN"; exit 1; fi; \
	SECRET_ID=$(SECRET_ID) KEY= MODE=$(MODE) OUT=$(OUT) AWS_REGION=$(AWS_REGION) "$$BIN"

# Convenience: fetch exactly one value (requires KEY). Same semantics as secrets-get KEY=...
secrets-get-value: ## [SECRET_ID=arn or name] [KEY=top-level or dotted json key] [OUT=] Fetch a single field from the secret (errors if missing)
	@BIN="$(CURDIR)/bin/secrets_get.sh"; \
	if [ -z "$(SECRET_ID)" ]; then echo "SECRET_ID is required"; exit 1; fi; \
	if [ -z "$(KEY)" ]; then echo "KEY is required"; exit 1; fi; \
	if [ ! -x "$$BIN" ]; then echo "Helper script not executable: $$BIN"; exit 1; fi; \
	SECRET_ID=$(SECRET_ID) KEY=$(KEY) OUT=$(OUT) AWS_REGION=$(AWS_REGION) "$$BIN"

.PHONY: s3-upload-file s3-upload-folder s3-download-file s3-download-folder secrets-get secrets-get-value
